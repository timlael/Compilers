P1
100 pts
Submission command:
/accounts/classes/janikowc/submitProject/submit_cs4280E01_P1
SubmitFileOrDirectory
Implement scanner for the lexical definitions
The scanner is embedded and thus it will return one token every time it is called by a parserdirected translator
Since the parser is not available yet, we will use a tester program, see below
The scanner could be implemented as
plain string reader assuming (75)
all tokens must be separated by spaces
lines not counted
implemented with switches/ifs
module generated by lex (75)
FSA table + driver (100)
In this case you must have the README file and state on your first line that you are using this
option table/driver plus an information on where the table data is. If this information is missing,
the project will be graded at 75.
Implement a token as a triplet {tokenID, tokenInstance, line#} (no line number for the first options) . TokenID can be
enumeration or symbolic constant, tokenInstance can be a string or can be some reference to a symbol table
Dont forget EOFtk token in either case

For testing purposes, this project is to keep displaying tokens one at a time. Every token should
be displayed to the screen, one token per line, listing line# (if available), some name identifying
the token (not just the enumerated value), and the instance string of the token if any.
Invocation:
   testScanner [file]
to scan from stdin or file file.4280E01. Note that the extension is implicit. That is if the source
is in project.4280E01 (sources must have extension .4280E01), then the correct invocation is
testScanner project and not testScanner project.4280E01.
reading from the keyboard should work with redirection from a file, as in P0
wrong invocations will not be graded
Graded 80% execution and 20% style
You must have (C++ can be accordingly different)
types including token type definition in token.h
implement scanner in scanner.c and scanner.h
implement the tester in another file testScanner.c and testScanner.h
main.c
file name or handle/pointer can be passed using globals or parameters
the same about the token but here scanner() function returning the token is probably better option

Lex Def
All case sensitive
Alphabet
all English letters (upper and lower), digits, plus the extra characters as seen below, plus WS

No other characters allowed and they should generate lexical errors

Each scanner error should display "Scanner Error:" followed by details.
Identifiers
begin with a letter and
continue with any number of letters
you may assume no identifier is longer than 8
Keywords (reserved, suggested individual tokens)
start stop decision while void int return read print program
Operators delimiters etc.
=  <<  >>  =!  == :  +  -  *  / & %  . (  ) , { } ; [
Integers
any sequence of decimal digits, no sign
you may assume no number longer than 8 digits
Comments start with # and end with WS



Suggestions
Suggestions for the FA option
have the scanner read the file through a filter. The filter will
skip over #...
count lines
construct the string
return column number instead of the actual character read
represent the DFA as 2-d array of type integer
0, 1, etc are numbers corresponding to the row for the next state
-1, -2, etc are different error cases
1000, 1001, etc are final states for different tokens (e.g. 1000 is for ID, etc)
do not distinguish keywords and IDs in the automaton, but when ID detected check if maybe
a keyword (to be a keyword, the ID must match one of the keywords exactly and completely
not partially so IF is a keyword but IFF is not
Suggestions for the string reader option (all tokens separated by spaces). The scanner function
would need to:
1. scanf (%s, data) reading up to white space so next token or comment (or EOF if fails)
2. If (data[0] == '#') skip since it is comment
3. if (isletter(data[0] and stringContainsLettersDigits(&data[1]) then ID so check against keywords
4. if(alldigits(data)) then it is integer
5. If (strlen of data) == 1 then check for
if data[0] == '+' then plusToken
etc
else error
6. If (strlenof data) == 2 then check the strings
if strcmp with ">>" then GreaterEqTk
etc
else error
7. Then check longer tokens, fewer of those
Token is a structure containing tokenID (can be enumerated or symbolic constants), instance (string) and line
number (int). It may be passed on the interface or through global token variable. If global, it should probably be
defined in token.c and prototyped as extern in scanner.h.

To print tokens I would suggest an array of strings describing the tokens, listed in the same order as the tokenID
enumeration. For example:
enum tokenID {IDENT_tk, NUM_tk, DEC_tk, etc};
string tokenNames[] ={"Identifier", "Number", "Decision keyword", etc};
struct token { tokenID, string, int};
Then printing tokenNames[tokenID] will print the token description.

Testing
Test the keyboard vs. file input but redirecting the input as in P0.
To test tokens, list all possible tokens separated by spaces and make sure you get them all followed by EOFtk. IF
using more complex scanner allowing no spaces, test some tokens without spaces such as :: or Iff()

Lex Errors
On any error, we print as detailed message as possible and exit processing.Lexical errors are 3 kinds:
1. Characters not in alphabet (not listed among those making any tokens)
2. Invalid token, for example 23a is invalid if tokens need to be separated by WS (if not needed separated then
it would be integer followed by identifier and thus not an error)
3. Source file cannot be open
